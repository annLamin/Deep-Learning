{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOAyneLOVQFn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import Input\n",
    "from random import randrange\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from array import array\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "import sys\n",
    "from matplotlib.pyplot import figure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5jmUrq4LQh3"
   },
   "source": [
    "One common approach to sequential series prediction is to use a type of recurrent neural network (RNN) called a long short-term memory (LSTM) network or a gated recurrent unit (GRU) network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fyHbPlWVlCa"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Italia-positivi-giornaliero.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUmwh_QnV8nl"
   },
   "outputs": [],
   "source": [
    "data = data.totale_positivi.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rjIYISU1WCNG"
   },
   "outputs": [],
   "source": [
    "def sequence_split(sequence, inp,outp):\n",
    "    from numpy import array\n",
    "    X,y  = list(),list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + inp  \n",
    "        if end_ix > len(sequence)-1: \n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix],sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pD6pA5tUtyF1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPrs49luWH7C"
   },
   "outputs": [],
   "source": [
    "X,y = sequence_split(data, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j6eaL9GeVTF4",
    "outputId": "2ea7ca9f-4f98-4b1d-8dc2-6dd9d56875da"
   },
   "outputs": [],
   "source": [
    "for i in X:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDHM6yPTWMyN"
   },
   "source": [
    "### IMPLEMENTING MLP WITH THE ITALIA-POSITIVI DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xdv6IPNEWgqV",
    "outputId": "fca747d0-aa38-44e7-cfb9-bd78f5db187c"
   },
   "outputs": [],
   "source": [
    "MLP = Sequential()\n",
    "MLP.add(Dense(50, activation = 'relu' , input_dim = 10))\n",
    "MLP.add(Dense(1))\n",
    "# MLP.add(Dense(128, activation = 'relu'))\n",
    "\n",
    "MLP.compile(optimizer = 'adam', loss = 'mse', metrics=['accuracy'])\n",
    "MLP.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "raOXhWB9Wh9K",
    "outputId": "5cb1e923-dc8b-400f-dbf1-a1e252499037"
   },
   "outputs": [],
   "source": [
    "history = MLP.fit(X,y, epochs = 500, batch_size = 128) # Fitting our data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14l8D2t8Wqtz"
   },
   "outputs": [],
   "source": [
    "# making a prediction using the following values\n",
    "pred_data = np.array([102859, 106920, 110659, 115112, 119230, 120875, 123396, 127085, 132513, 137130])\n",
    "pred_data = pred_data.reshape(1,X.shape[1])\n",
    "y_hat = MLP.predict(pred_data, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lw39Ye7jW4Y4",
    "outputId": "a0130d19-2d63-44a9-f0df-b540cfcc95c8"
   },
   "outputs": [],
   "source": [
    "print(\"Predicted Value\",y_hat)  # printing our predicted value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "Aew40QlkXClg",
    "outputId": "745be9b2-895e-48c6-cb49-10a920a8585f"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_egaNODoXQyM"
   },
   "source": [
    "### Experimenting on MobyDict dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqPa7TZLYK0A"
   },
   "outputs": [],
   "source": [
    "trend_data = pd.read_csv('Italia-trend-giornaliero.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJPZ-jsSYZ4N"
   },
   "outputs": [],
   "source": [
    "trend_data.drop(trend_data.columns[2:], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nfi8AuLFZ-lP",
    "outputId": "ef6f68de-fd7a-434b-e85f-77ee315bb33b"
   },
   "outputs": [],
   "source": [
    "trend_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "6x8cVVnaa7vj",
    "outputId": "fdc1c9f3-df09-436e-f4ea-1fab5de30c97"
   },
   "outputs": [],
   "source": [
    "trend_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NVgmLRg0hQ5l"
   },
   "outputs": [],
   "source": [
    "trend_data = trend_data.ricoverati.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qj2r32WEhh09"
   },
   "outputs": [],
   "source": [
    "X_trend,y_trend = sequence_split(trend_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IvaCWEayhsar",
    "outputId": "2d755b97-6423-4f4e-cc64-95cf0b3cb55d"
   },
   "outputs": [],
   "source": [
    "for x in X_trend: \n",
    "  print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd9nIrk3htNu",
    "outputId": "6004844b-e569-4421-f7b4-303d5350bed8"
   },
   "outputs": [],
   "source": [
    "history = MLP.fit(X_trend,y_trend, epochs = 200, batch_size = 128) # Fitting our data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rOdP8YgIicsh",
    "outputId": "484d5889-6940-4a0e-e6ad-6aa0e59ae9bb"
   },
   "outputs": [],
   "source": [
    "pred_data = np.array([3525, 3597 ,3647, 3808 ,3970, 4060, 4088 ,4145 ,4250 ,4345]) # making a prediction\n",
    "pred_data = pred_data.reshape(1,X_trend.shape[1])\n",
    "y_hat = MLP.predict(pred_data, verbose=0)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "x0dZIJqGizga",
    "outputId": "bbe87867-19e1-47f6-b16f-20acb89ce553"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISD_nWpfjEhi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfRPuX8ltfX9"
   },
   "source": [
    "### Implementing the MobyDict Dataset  taking part of the dataset for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9aE5j54Dxdq7"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QfQT1bmNmDu_"
   },
   "outputs": [],
   "source": [
    "# file = open(\"MobyDick.txt\", mode=\"r\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noHHHQ1LtkAl"
   },
   "outputs": [],
   "source": [
    "moby_data = \"\"\" It had cooled and crystallized to such a degree, that when, with several others, I sat down before a large Constantineâ€™s bath of it, I found it strangely concreted into lumps, here and there rolling about in the liquid part. It was our business to squeeze these lumps backinto fluid. /n\n",
    "A sweet and unctuous duty! No wonder that in old times this sperm was such a favourite cosmetic. /n\n",
    "Such a clearer! such a sweetener! such a softener! such a delicious molifier! After having my hands in it for only a few minutes, my fingers felt like eels, and began, as it were, to serpentine and spiralise. /n\n",
    "As I sat there at my ease, cross-legged on the deck; after the bitter exertion at the windlass; under a blue tranquil sky; the ship under indolent sail, and gliding so serenely along; /n\n",
    "as I bathed my hands among those soft, gentle globules of infiltrated tissues, woven almost within the hour; as they richly broke to my fingers, and discharged all their opulence, like fully ripe grapes their wine; /n\n",
    "as I snuffed up that uncontaminated aroma,â€”literally and truly, like the smell of spring violets; /n\n",
    "I declare to you, that for the time I lived as in a musky meadow; /n\n",
    "I forgot all about our horrible oath; in that inexpressible sperm, I washed my hands and my heart of it; /n\n",
    "I almost began to credit the old Paracelsan superstition that sperm is of rare virtue in allaying the heat of anger; while bathing in that bath, I felt divinely free from all ill-will, or petulance, or malice, of any sort whatsoever.\n",
    "\\n \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U_6y4_VYuLxx",
    "outputId": "4b68a281-31ef-4819-b20e-f7064f9ef8e9"
   },
   "outputs": [],
   "source": [
    "# We convert all this the words into numbers by fitting  in the texts\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([moby_data])\n",
    "encoded_data = tokenizer.texts_to_sequences([moby_data])[0]\n",
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qg7ZPBnJyGtN",
    "outputId": "98591964-1581-43e8-e7e1-f0af4949f893"
   },
   "outputs": [],
   "source": [
    "text_size = len(tokenizer.word_index) + 1\n",
    "text_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vsA8RJDHzZqL",
    "outputId": "b67daa14-7241-41be-f87f-3026193697ef"
   },
   "outputs": [],
   "source": [
    "from keras.utils.timeseries_dataset import sequences_from_indices\n",
    "# Creating a sequence of words to fit the model with input and output datas\n",
    "\n",
    "sequences = list() # creating an empty list\n",
    "for i in range(1, len(encoded_data)):\n",
    "  sequence = encoded_data[i-1:i+1]\n",
    "  sequences.append(sequence)\n",
    "print(\"The length of the sequence is: \",len(sequences))\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_5B_ywX38Ny"
   },
   "outputs": [],
   "source": [
    "# Splitting the data into input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jlG0ibv4hxO"
   },
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)\n",
    "inp, outp = sequences[:,0], sequences[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G9iVhP9Z5Am1",
    "outputId": "908bdaae-74c7-4558-da36-7c819833439b"
   },
   "outputs": [],
   "source": [
    "inp[:10],outp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AVAfhZ7l6VrJ",
    "outputId": "50bc8273-347f-480d-f894-ffeaf97109fe"
   },
   "outputs": [],
   "source": [
    "outp = to_categorical(outp, num_classes=text_size) # creating a one hot encoding\n",
    "outp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1t1gwM3v64RS"
   },
   "outputs": [],
   "source": [
    "# Building our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rxwc4UhB8UUe",
    "outputId": "5e2bee13-ca37-42f3-b8ac-9aa41a51e9f9"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(text_size, 50, input_length=1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(text_size, activation = 'softmax'))\n",
    "# model.add(Dense(10))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inW0BFrD9EDa"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GDLTj6Qy9eIq",
    "outputId": "49b46bb9-4c56-4034-f6f7-a0a2ef7d1252"
   },
   "outputs": [],
   "source": [
    "model.fit(inp, outp, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rq-1Fomk9miE"
   },
   "outputs": [],
   "source": [
    "#  generating a sequence from the model\n",
    "\n",
    "def generate_seg(model, tokenizer, enter_text, n_pred):\n",
    "  in_text, result = enter_text, enter_text\n",
    "  for _ in range(n_pred):\n",
    "    encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "    encoded = array(encoded)\n",
    "\n",
    "    y_pred = model.predict(encoded).any()\n",
    "    out_word = ''\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "      if index == y_pred:\n",
    "        out_word = word\n",
    "        break\n",
    "    in_text, result = out_word, result + ' ' + out_word\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "we2Diwku_kAQ",
    "outputId": "6a6558b1-e3a8-4dc4-a417-ae89070a2ba1"
   },
   "outputs": [],
   "source": [
    "print(generate_seg(model, tokenizer, 'bitter', 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3PgpejeB8NL"
   },
   "outputs": [],
   "source": [
    "# MLP WITH MOBY-DICK DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SxeROL0k_1AY"
   },
   "outputs": [],
   "source": [
    "# Implementing the Covid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "jN_YvVsVMcwW",
    "outputId": "db3365c6-8fce-4b9a-d61d-79a551d81d62"
   },
   "outputs": [],
   "source": [
    "covid_data = pd.read_csv('TotalPositiveVariation.csv')\n",
    "covid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3sATWZP3MuEH",
    "outputId": "48061c32-362d-408d-d5d3-603c74c5612e"
   },
   "outputs": [],
   "source": [
    "covid_data = covid_data.variazione_totale_positivi.values.tolist()\n",
    "covid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edALRieNM11q"
   },
   "outputs": [],
   "source": [
    "covid_X,covid_y = sequence_split(covid_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xtMp6bowNTxa",
    "outputId": "b1a78f80-a7f6-411a-a104-9af459ca0d56"
   },
   "outputs": [],
   "source": [
    "covid_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CtPOLHCGNVjm",
    "outputId": "85355300-3ac9-47fd-f7ae-6bc0a8ea9fcf"
   },
   "outputs": [],
   "source": [
    "for cov in covid_X:\n",
    "  print(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wk7WNbdGNcCS",
    "outputId": "7f5575dd-5be8-481b-cb8e-1d516a7717ac"
   },
   "outputs": [],
   "source": [
    "covid_history = MLP.fit(covid_X,covid_y, epochs = 100, batch_size = 128) # Fitting our data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7SoL65zwN2Qq",
    "outputId": "3abc6d12-9939-4d57-8ea3-87cd1b489a6b"
   },
   "outputs": [],
   "source": [
    "pred_data = np.array([3739 ,4453, 4118, 1645 ,2521 ,3689, 5428, 4617, 6271 ,5359]) # making a prediction\n",
    "pred_data = pred_data.reshape(1,covid_X.shape[1])\n",
    "y_hat = MLP.predict(pred_data, verbose=0)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xE6XqeH_RqAc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "lcfrj0IWO9Iv",
    "outputId": "dcd7ea82-22ea-4299-c231-fba41fcc5318"
   },
   "outputs": [],
   "source": [
    "plt.plot(covid_history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_AFNIhMPEhQ"
   },
   "source": [
    "#### Question 2 IMPLEMENTING THE ABOVE IN RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "a6gCUsonPkIo",
    "outputId": "92d2fa3b-bc45-4dc1-e8d7-3c43db51ef44"
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_dataset(time_steps, num_examples, input_dim, output_dim):\n",
    "    X = np.random.randn(num_examples, time_steps, input_dim)\n",
    "    y = np.random.randn(num_examples, output_dim)\n",
    "    return X, y\n",
    "\n",
    "# Define the LSTM model\n",
    "def build_model(time_steps, input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(32, input_shape=(time_steps, input_dim)))\n",
    "    model.add(Dense(output_dim))\n",
    "    return model\n",
    "\n",
    "# Generate the dataset\n",
    "time_steps = 10\n",
    "input_dim = 1\n",
    "output_dim = 1\n",
    "X, y = generate_dataset(time_steps, 100, input_dim, output_dim)\n",
    "\n",
    "# Build and compile the model\n",
    "model = build_model(time_steps, input_dim, output_dim)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Fit the model to the data\n",
    "history = model.fit(X, y, epochs=100, verbose=0)\n",
    "\n",
    "# Predict the output\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Plot the predicted values\n",
    "plt.plot(predictions, 'r', label='Predicted')\n",
    "plt.plot(y, 'b', label='Actual Value')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7cLvSSjUTa3"
   },
   "outputs": [],
   "source": [
    "X,y = sequence_split(data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rYxHZDVGUX0Y",
    "outputId": "4156172c-2e43-40d8-c0f3-c44292f0785c"
   },
   "outputs": [],
   "source": [
    "for values in X:\n",
    "  print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vKU7-h0UUDcA",
    "outputId": "e6d3fe80-7274-43a5-e961-a96152a0af7a"
   },
   "outputs": [],
   "source": [
    "from keras.layers import RNN, SimpleRNN\n",
    "from keras.models import Sequential\n",
    "\n",
    "# define the model\n",
    "RNN = Sequential()\n",
    "RNN.add(SimpleRNN(50, input_shape=(None, 1)))\n",
    "\n",
    "# compile the model\n",
    "RNN.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# fit the model to the data\n",
    "history = RNN.fit(X, y, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y5AfUw6oUfla"
   },
   "outputs": [],
   "source": [
    "pred_data = np.array([110659, 115112, 119230 ,120875, 123396, 127085 ,132513, 137130, 143401 ,148760]) # making a prediction\n",
    "pred_data = pred_data.reshape(1,X.shape[1])\n",
    "y_hat = RNN.predict(pred_data, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "B3NbVBJzVLpB",
    "outputId": "c41496b7-1de9-468d-8b7f-7dd4f22f8c81"
   },
   "outputs": [],
   "source": [
    "predictions = RNN.predict(X)\n",
    "\n",
    "# Plot the predicted values\n",
    "plt.plot(predictions, 'r', label='Predicted')\n",
    "plt.plot(y, 'b', label='Actual Value')\n",
    "# plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "KLFRbrQbH7gt",
    "outputId": "b7760ba6-316a-4d01-b6d8-650256662ccb"
   },
   "outputs": [],
   "source": [
    "predictions = RNN.predict(X)\n",
    "\n",
    "# Plot the predicted values\n",
    "plt.plot(y_hat, 'r', label='Predicted')\n",
    "plt.plot(y, 'b', label='Actual Value')\n",
    "# plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Y_sdUh1VPlT"
   },
   "source": [
    "#### Implementing LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GOEzta70Izba"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Italia-trend-giornaliero.csv',parse_dates = ['data'], index_col = ['data'])\n",
    "df.drop(df.columns[2:], axis=1, inplace=True)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "df = scaler.fit_transform(df)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "split_index = int(len(df) * 0.8)\n",
    "x_train, y_train = df[:split_index, :-1], df[:split_index, -1]\n",
    "x_test, y_test = df[split_index:, :-1], df[split_index:, -1]\n",
    "\n",
    "# Reshape the data for the LSTM\n",
    "x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(1, x_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Fit the model to the training data\n",
    "trend_history = model.fit(x_train, y_train, epochs=100, batch_size=16, validation_data=(x_test, y_test), verbose=2, shuffle=False)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "S7eaPzibVmTj",
    "outputId": "5278a1ea-62f3-48b7-bab7-136d68811cc1"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(y_test, label='True')\n",
    "plt.plot(predictions[:, 0], label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "9BQilTb7JQLV",
    "outputId": "9b77ca2d-98ed-43a3-c8e9-28d88f32bdf9"
   },
   "outputs": [],
   "source": [
    "plt.plot(trend_history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4XnKrmMGXnvu"
   },
   "outputs": [],
   "source": [
    "#### Implementing GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pSCTKPOTY98-",
    "outputId": "63bccc16-748d-420f-d40e-ae48165daec7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Dense\n",
    "\n",
    "df = pd.read_csv('Italia-trend-giornaliero.csv',parse_dates = ['data'], index_col = ['data'])\n",
    "df.drop(df.columns[2:], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "df = scaler.fit_transform(df)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "split_index = int(len(df) * 0.8)\n",
    "x_train, y_train = df[:split_index, :-1], df[:split_index, -1]\n",
    "x_test, y_test = df[split_index:, :-1], df[split_index:, -1]\n",
    "\n",
    "# Reshape the data for the GRU\n",
    "x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(GRU(64, input_shape=(1, x_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "# Fit the model to the training data\n",
    "trend_hist = model.fit(x_train, y_train, epochs=100, batch_size=16,validation_data=(x_test, y_test), verbose=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "2Tew0AX9ZQUs",
    "outputId": "a0dd5dae-6843-40d5-ac8b-366346ba5e19"
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Unnormalize the data\n",
    "# predictions = scaler.inverse_transform(predictions)\n",
    "# y_test = scaler.inverse_transform([y_test])\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(y_test, label='True')\n",
    "plt.plot(predictions[:, 0], label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "OQo1rOG5ZVPj",
    "outputId": "7c7253dd-5e22-4819-e921-a2e541c64e6f"
   },
   "outputs": [],
   "source": [
    "print(trend_history.history.keys())\n",
    "#  \"Accuracy\"\n",
    "plt.plot(trend_hist.history['accuracy'])\n",
    "plt.plot(trend_history.history['loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "RouUudpJb-0p",
    "outputId": "a89a6bb2-d43c-4568-9cf5-ee574923c58c"
   },
   "outputs": [],
   "source": [
    "plt.plot(trend_history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AO9neqjpgyrW"
   },
   "outputs": [],
   "source": [
    "# The Italia positivi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJmwkbIWkDPm"
   },
   "outputs": [],
   "source": [
    "for i in X:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fu3-pfvjjLg"
   },
   "outputs": [],
   "source": [
    "positivi_history = GRU.fit(X,y, epochs = 100, batch_size = 128) # Fitting our data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "NF9p7qekgdZd",
    "outputId": "a2d58278-3a68-4b92-9d9b-485d792eb1ac"
   },
   "outputs": [],
   "source": [
    "predictions = GRU.predict(y)\n",
    "\n",
    "pred_data = np.array([115112 ,119230 ,120875 ,123396, 127085, 132513, 137130, 143401 ,148760,151514]) # making a prediction\n",
    "pred_data = pred_data.reshape(1,X.shape[1])\n",
    "y_hat = GRU.predict(pred_data, verbose=0)\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(y_test, label='True')\n",
    "plt.plot(predictions[:, 0], label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xIUPdFz8pdQG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XqDvEqcjg5PA",
    "outputId": "10abfd84-7ee3-484c-d8dd-83731db32088"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Dense\n",
    "\n",
    "# Load the dataset\n",
    "pos_data = pd.read_csv('Italia-positivi-giornaliero.csv')\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "pos_data = scaler.fit_transform(pos_data)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "split_index = int(len(pos_data) * 0.8)\n",
    "x_train, y_train = pos_data[:split_index, :-1], pos_data[:split_index, -1]\n",
    "x_test, y_test = pos_data[split_index:, :-1], pos_data[split_index:, -1]\n",
    "print(x_test)\n",
    "# Reshape the data for the GRU\n",
    "x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "# Build the model\n",
    "gru = Sequential()\n",
    "gru.add(GRU(64, input_shape=(1, x_train.shape[2])))\n",
    "gru.add(Dense(1))\n",
    "gru.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Fit the model to the training data\n",
    "GRU_history = gru.fit(x_train, y_train, epochs=10, batch_size=16, validation_data=(x_test, y_test), verbose=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "AEGt8wHVqCfP",
    "outputId": "c9168bb5-2260-4e89-aba0-3d96889b5ba9"
   },
   "outputs": [],
   "source": [
    "plt.plot(GRU_history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIEGNeUqqkU1"
   },
   "source": [
    "### THE PI DATASET IMPLEMENTATION USING MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QESmbp49pqu0"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.set_int_max_str_digits(int(10E6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z6rSrIa5n3aA",
    "outputId": "839c07a5-c405-4188-f871-f9e8a90f0d04"
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('pi1000000.txt') as f:\n",
    "  pi_data = f.readlines()\n",
    "pi_data = np.array(pi_data)\n",
    "pi_data = pi_data[0][2:]\n",
    "sys.set_int_max_str_digits(int(10E6))\n",
    "pi_data = int(pi_data)\n",
    "  \n",
    "pi_data = str(pi_data)\n",
    "pi_data = np.array([ int(i) for i in pi_data ])\n",
    "pi_data = pi_data.flatten()\n",
    "print(pi_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMYSp1xUpgDS"
   },
   "outputs": [],
   "source": [
    "def split_array(data_array, predictors = 10):\n",
    "    split_data = []\n",
    "\n",
    "    # define input sequence\n",
    "    seq = np.arange(predictors)\n",
    "\n",
    "    i = 1\n",
    "    start = predictors \n",
    "    seq = np.arange(start)\n",
    "    \n",
    "    while i > 0 and start > 0:\n",
    "        split_data.append(data_array[ start-1: -i])\n",
    "        i+=1\n",
    "        start-=1\n",
    "\n",
    "    return split_data, seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RR3cZIFmshvj",
    "outputId": "20b9d132-b893-40fe-99db-cea7865234a8"
   },
   "outputs": [],
   "source": [
    "pi_data[:1000][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YEFKXEfWsiq4",
    "outputId": "6e1e80ff-5b68-4d28-97fa-ad26901afff1"
   },
   "outputs": [],
   "source": [
    "split_data, seq = split_array(pi_data[:1000])\n",
    "split_data = np.array(split_data)\n",
    "split_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hym37-Hswyt"
   },
   "outputs": [],
   "source": [
    "output_k = []\n",
    "for i in seq:\n",
    "    raw_seq = split_data[i]\n",
    "    n_steps_in, n_steps_out = 20, i + 1\n",
    "    X, y = sequence_split(raw_seq, n_steps_in, n_steps_out)\n",
    "    # define model\n",
    "    model = Sequential()   \n",
    "    model.add(Dense(100, activation='relu', input_dim=n_steps_in))\n",
    "    model.add(Dense(n_steps_out))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    # fit model\n",
    "    pi_history =model.fit(X, y, epochs=300, verbose=0)\n",
    "    # demonstrate prediction\n",
    "    x_input = split_data[i][-n_steps_in:]\n",
    "    x_input = x_input.reshape((1, n_steps_in))\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    \n",
    "    output_k.append(yhat[-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "8JNXpbIa6GXq",
    "outputId": "cf3a21ae-977a-4ce7-a83a-c788cc81e5c0"
   },
   "outputs": [],
   "source": [
    "plt.plot(pi_history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DVRT0r0-tbF1",
    "outputId": "01204d0d-cb3d-469a-c12c-207413ed3ab5"
   },
   "outputs": [],
   "source": [
    "output_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBL1bdqYwAsm",
    "outputId": "e620ed02-e458-4729-eb92-02f7802eb002"
   },
   "outputs": [],
   "source": [
    "np.mean(output_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2kf9p7kRwXQO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
