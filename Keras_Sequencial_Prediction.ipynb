{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe55230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c116f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Class','x-box','y-box','width','high','onpix','x-bar','y-bar','x2bar','y2bar','xybar','x2ybr','xy2br','x-ege','xegvy','y-ege','yegvx']\n",
    "\n",
    "data = pd.read_csv(\"../Datasets/letters.csv\",names = names)\n",
    "#data = pd.read_csv(\"letters.csv\",names = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c88dfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Class  x-box  y-box  width  high  onpix  x-bar  y-bar  x2bar  y2bar  \\\n",
      "0         T      0      8      3     5      1      8     13      0      6   \n",
      "1         I      0     12      3     7      2     10      5      5      4   \n",
      "2         D      0     11      6     8      6     10      6      2      6   \n",
      "3         N      0     11      6     6      3      5      9      4      6   \n",
      "4         G      0      1      3     1      1      8      6      6      6   \n",
      "...     ...    ...    ...    ...   ...    ...    ...    ...    ...    ...   \n",
      "19995     D      2      2      3     3      2      7      7      7      6   \n",
      "19996     C      7     10      8     8      4      4      8      6      9   \n",
      "19997     T      6      9      6     7      5      6     11      3      7   \n",
      "19998     S      2      3      4     2      1      8      7      2      6   \n",
      "19999     A      4      9      6     6      2      9      5      3      1   \n",
      "\n",
      "       xybar  x2ybr  xy2br  x-ege  xegvy  y-ege  yegvx  \n",
      "0          6     10      8      0      8      0      8  \n",
      "1         13      3      9      2      8      4     10  \n",
      "2         10      3      7      3      7      3      9  \n",
      "3          4      4     10      6     10      2      8  \n",
      "4          6      5      9      1      7      5     10  \n",
      "...      ...    ...    ...    ...    ...    ...    ...  \n",
      "19995      6      6      4      2      8      3      0  \n",
      "19996     12      9     13      2      9      3      0  \n",
      "19997     11      9      5      2     12      2      0  \n",
      "19998     10      6      8      1      9      5      0  \n",
      "19999      8      1      8      2      7      2      0  \n",
      "\n",
      "[320000 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "DS = []\n",
    "for i in range(1,len(data.columns)):\n",
    "    DS_new = data.assign()\n",
    "#     print(mean(DS_new)) \n",
    "    DS_new.iloc[:,i]= 0\n",
    "    DS.append(DS_new)\n",
    "    df=pd.concat(DS)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8426597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-box</th>\n",
       "      <th>y-box</th>\n",
       "      <th>width</th>\n",
       "      <th>high</th>\n",
       "      <th>onpix</th>\n",
       "      <th>x-bar</th>\n",
       "      <th>y-bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybr</th>\n",
       "      <th>xy2br</th>\n",
       "      <th>x-ege</th>\n",
       "      <th>xegvy</th>\n",
       "      <th>y-ege</th>\n",
       "      <th>yegvx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>320000.000000</td>\n",
       "      <td>320000.000000</td>\n",
       "      <td>320000.000000</td>\n",
       "      <td>320000.000000</td>\n",
       "      <td>320000.000000</td>\n",
       "      <td>320000.000000</td>\n",
       "      <td>320000.000000</td>\n",
       "      <td>320000.000000</td>\n",
       "      <td>320000.000000</td>\n",
       "      <td>320000.000000</td>\n",
       "      <td>320000.000000</td>\n",
       "      <td>320000.000000</td>\n",
       "      <td>320000.000000</td>\n",
       "      <td>320000.000000</td>\n",
       "      <td>320000.000000</td>\n",
       "      <td>320000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.772078</td>\n",
       "      <td>6.595781</td>\n",
       "      <td>4.801734</td>\n",
       "      <td>5.036672</td>\n",
       "      <td>3.286734</td>\n",
       "      <td>6.466500</td>\n",
       "      <td>7.031672</td>\n",
       "      <td>4.339313</td>\n",
       "      <td>4.854984</td>\n",
       "      <td>7.764422</td>\n",
       "      <td>6.050625</td>\n",
       "      <td>7.433438</td>\n",
       "      <td>2.855719</td>\n",
       "      <td>7.817672</td>\n",
       "      <td>3.461016</td>\n",
       "      <td>7.313625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.092849</td>\n",
       "      <td>3.624555</td>\n",
       "      <td>2.311230</td>\n",
       "      <td>2.546616</td>\n",
       "      <td>2.284336</td>\n",
       "      <td>2.576006</td>\n",
       "      <td>2.892297</td>\n",
       "      <td>2.844153</td>\n",
       "      <td>2.623966</td>\n",
       "      <td>3.134374</td>\n",
       "      <td>2.988352</td>\n",
       "      <td>2.782439</td>\n",
       "      <td>2.375739</td>\n",
       "      <td>2.513391</td>\n",
       "      <td>2.641265</td>\n",
       "      <td>2.453270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               x-box          y-box          width           high  \\\n",
       "count  320000.000000  320000.000000  320000.000000  320000.000000   \n",
       "mean        3.772078       6.595781       4.801734       5.036672   \n",
       "std         2.092849       3.624555       2.311230       2.546616   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         2.000000       4.000000       4.000000       3.000000   \n",
       "50%         4.000000       7.000000       5.000000       5.000000   \n",
       "75%         5.000000       9.000000       6.000000       7.000000   \n",
       "max        15.000000      15.000000      15.000000      15.000000   \n",
       "\n",
       "               onpix          x-bar          y-bar          x2bar  \\\n",
       "count  320000.000000  320000.000000  320000.000000  320000.000000   \n",
       "mean        3.286734       6.466500       7.031672       4.339313   \n",
       "std         2.284336       2.576006       2.892297       2.844153   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         2.000000       5.000000       6.000000       2.000000   \n",
       "50%         3.000000       7.000000       7.000000       4.000000   \n",
       "75%         5.000000       8.000000       8.000000       6.000000   \n",
       "max        15.000000      15.000000      15.000000      15.000000   \n",
       "\n",
       "               y2bar          xybar          x2ybr          xy2br  \\\n",
       "count  320000.000000  320000.000000  320000.000000  320000.000000   \n",
       "mean        4.854984       7.764422       6.050625       7.433438   \n",
       "std         2.623966       3.134374       2.988352       2.782439   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         3.000000       6.000000       5.000000       6.000000   \n",
       "50%         5.000000       7.000000       6.000000       8.000000   \n",
       "75%         7.000000      10.000000       8.000000       9.000000   \n",
       "max        15.000000      15.000000      15.000000      15.000000   \n",
       "\n",
       "               x-ege          xegvy          y-ege          yegvx  \n",
       "count  320000.000000  320000.000000  320000.000000  320000.000000  \n",
       "mean        2.855719       7.817672       3.461016       7.313625  \n",
       "std         2.375739       2.513391       2.641265       2.453270  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         1.000000       7.000000       1.000000       7.000000  \n",
       "50%         3.000000       8.000000       3.000000       8.000000  \n",
       "75%         4.000000       9.000000       5.000000       8.000000  \n",
       "max        15.000000      15.000000      15.000000      15.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5a072a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:17]\n",
    "Y = df.select_dtypes(include=[object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfb38520",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test, y_train, y_test= model_selection.train_test_split(X,Y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8607c614",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(50, 60), max_iter=1000, activation='logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69da91d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=(50, 60), max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=(50, 60), max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(50, 60), max_iter=1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3025645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.955586\n",
      "Test set score: 0.949281\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set score: %f\" % mlp.score(x_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51e6d3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.98      0.98      0.98      2443\n",
      "           B       0.92      0.93      0.93      2412\n",
      "           C       0.97      0.94      0.96      2423\n",
      "           D       0.93      0.95      0.94      2539\n",
      "           E       0.94      0.92      0.93      2499\n",
      "           F       0.95      0.94      0.94      2472\n",
      "           G       0.93      0.93      0.93      2535\n",
      "           H       0.89      0.92      0.90      2364\n",
      "           I       0.95      0.96      0.96      2400\n",
      "           J       0.96      0.94      0.95      2364\n",
      "           K       0.92      0.94      0.93      2337\n",
      "           L       0.98      0.96      0.97      2542\n",
      "           M       0.98      0.96      0.97      2650\n",
      "           N       0.95      0.96      0.96      2439\n",
      "           O       0.91      0.95      0.93      2436\n",
      "           P       0.94      0.97      0.95      2578\n",
      "           Q       0.94      0.94      0.94      2510\n",
      "           R       0.91      0.93      0.92      2392\n",
      "           S       0.94      0.96      0.95      2407\n",
      "           T       0.97      0.96      0.96      2481\n",
      "           U       0.97      0.95      0.96      2609\n",
      "           V       0.97      0.95      0.96      2427\n",
      "           W       0.98      0.97      0.98      2391\n",
      "           X       0.96      0.95      0.95      2506\n",
      "           Y       0.97      0.96      0.96      2522\n",
      "           Z       0.98      0.96      0.97      2322\n",
      "\n",
      "    accuracy                           0.95     64000\n",
      "   macro avg       0.95      0.95      0.95     64000\n",
      "weighted avg       0.95      0.95      0.95     64000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ad06e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'Pedigree', 'Age']\n",
      "Epoch 1/34\n",
      "491/491 [==============================] - 2s 3ms/step - loss: 0.6512 - accuracy: 0.3320 - val_loss: 0.6351 - val_accuracy: 0.3415\n",
      "Epoch 2/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.4277 - accuracy: 0.5153 - val_loss: 0.3246 - val_accuracy: 0.5610\n",
      "Epoch 3/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2530 - accuracy: 0.6415 - val_loss: 0.2459 - val_accuracy: 0.6341\n",
      "Epoch 4/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2418 - accuracy: 0.6477 - val_loss: 0.2310 - val_accuracy: 0.6423\n",
      "Epoch 5/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2299 - accuracy: 0.6538 - val_loss: 0.2305 - val_accuracy: 0.6423\n",
      "Epoch 6/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2273 - accuracy: 0.6558 - val_loss: 0.2301 - val_accuracy: 0.6423\n",
      "Epoch 7/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2267 - accuracy: 0.6558 - val_loss: 0.2299 - val_accuracy: 0.6423\n",
      "Epoch 8/34\n",
      "491/491 [==============================] - 1s 3ms/step - loss: 0.2263 - accuracy: 0.6558 - val_loss: 0.2298 - val_accuracy: 0.6423\n",
      "Epoch 9/34\n",
      "491/491 [==============================] - 1s 3ms/step - loss: 0.2261 - accuracy: 0.6558 - val_loss: 0.2298 - val_accuracy: 0.6423\n",
      "Epoch 10/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2260 - accuracy: 0.6558 - val_loss: 0.2298 - val_accuracy: 0.6423\n",
      "Epoch 11/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2259 - accuracy: 0.6558 - val_loss: 0.2298 - val_accuracy: 0.6423\n",
      "Epoch 12/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2259 - accuracy: 0.6558 - val_loss: 0.2298 - val_accuracy: 0.6423\n",
      "Epoch 13/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2259 - accuracy: 0.6558 - val_loss: 0.2298 - val_accuracy: 0.6423\n",
      "Epoch 14/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2259 - accuracy: 0.6558 - val_loss: 0.2298 - val_accuracy: 0.6423\n",
      "Epoch 15/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2259 - accuracy: 0.6558 - val_loss: 0.2298 - val_accuracy: 0.6423\n",
      "Epoch 16/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.6558 - val_loss: 0.2299 - val_accuracy: 0.6423\n",
      "Epoch 17/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.6558 - val_loss: 0.2299 - val_accuracy: 0.6423\n",
      "Epoch 18/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.6558 - val_loss: 0.2299 - val_accuracy: 0.6423\n",
      "Epoch 19/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.6558 - val_loss: 0.2299 - val_accuracy: 0.6423\n",
      "Epoch 20/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.6558 - val_loss: 0.2299 - val_accuracy: 0.6423\n",
      "Epoch 21/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.6558 - val_loss: 0.2299 - val_accuracy: 0.6423\n",
      "Epoch 22/34\n",
      "491/491 [==============================] - 1s 3ms/step - loss: 0.2258 - accuracy: 0.6558 - val_loss: 0.2299 - val_accuracy: 0.6423\n",
      "Epoch 23/34\n",
      "491/491 [==============================] - 1s 3ms/step - loss: 0.2258 - accuracy: 0.6558 - val_loss: 0.2299 - val_accuracy: 0.6423\n",
      "Epoch 24/34\n",
      "491/491 [==============================] - 1s 3ms/step - loss: 0.2258 - accuracy: 0.6558 - val_loss: 0.2299 - val_accuracy: 0.6423\n",
      "Epoch 25/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.6558 - val_loss: 0.2299 - val_accuracy: 0.6423\n",
      "Epoch 26/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.6558 - val_loss: 0.2299 - val_accuracy: 0.6423\n",
      "Epoch 27/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.6558 - val_loss: 0.2300 - val_accuracy: 0.6423\n",
      "Epoch 28/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.6558 - val_loss: 0.2299 - val_accuracy: 0.6423\n",
      "Epoch 29/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.6558 - val_loss: 0.2299 - val_accuracy: 0.6423\n",
      "Epoch 30/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.6558 - val_loss: 0.2299 - val_accuracy: 0.6423\n",
      "Epoch 31/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2259 - accuracy: 0.6558 - val_loss: 0.2299 - val_accuracy: 0.6423\n",
      "Epoch 32/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.6558 - val_loss: 0.2299 - val_accuracy: 0.6423\n",
      "Epoch 33/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.6558 - val_loss: 0.2299 - val_accuracy: 0.6423\n",
      "Epoch 34/34\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.6558 - val_loss: 0.2299 - val_accuracy: 0.6423\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "properties = list(df.columns.values)\n",
    "properties.remove('Outcome')\n",
    "print(properties)\n",
    "X = df[properties]\n",
    "y = df['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(8,)),\n",
    "    keras.layers.Dense(4, activation=tf.nn.relu),\n",
    "\tkeras.layers.Dense(4, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=34, batch_size=1, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b8effa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
