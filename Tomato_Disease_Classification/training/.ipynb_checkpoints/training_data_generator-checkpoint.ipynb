{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c47e2438-422b-4318-aa05-397be54909d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f84d1cf-5e3d-4260-a311-ec03920b658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea831832-cf27-4be3-b017-d5cf72242825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11203 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range = 10,\n",
    "    \n",
    ")\n",
    "train_generator =train_datagen.flow_from_directory(\n",
    "    'dataset/train',\n",
    "    target_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'sparse',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38ab3e9b-e446-4422-91f5-40e5d176c06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.6058223  0.55484194 0.5234694 ]\n",
      "  [0.62638634 0.57540596 0.5440334 ]\n",
      "  [0.63429004 0.58330965 0.5519371 ]\n",
      "  ...\n",
      "  [0.64138377 0.5864818  0.5511877 ]\n",
      "  [0.6441612  0.58925927 0.55396515]\n",
      "  [0.6469387  0.5920367  0.5567426 ]]\n",
      "\n",
      " [[0.6044336  0.5534532  0.52208066]\n",
      "  [0.6252291  0.57424873 0.5428761 ]\n",
      "  [0.6340586  0.5830782  0.55170566]\n",
      "  ...\n",
      "  [0.56528974 0.5103878  0.47509363]\n",
      "  [0.5564944  0.50159246 0.46629837]\n",
      "  [0.54769915 0.4927972  0.45750308]]\n",
      "\n",
      " [[0.60304487 0.5520645  0.52069193]\n",
      "  [0.62407184 0.57309145 0.5417189 ]\n",
      "  [0.63382715 0.58284676 0.5514742 ]\n",
      "  ...\n",
      "  [0.5711685  0.5162665  0.48097238]\n",
      "  [0.57695484 0.5220529  0.48675874]\n",
      "  [0.5827412  0.52783924 0.49254513]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.6303685  0.5793881  0.54801553]\n",
      "  [0.630137   0.57915664 0.5477841 ]\n",
      "  [0.6299056  0.5789252  0.54755265]\n",
      "  ...\n",
      "  [0.6367899  0.58188796 0.5309076 ]\n",
      "  [0.5743432  0.51944125 0.4684608 ]\n",
      "  [0.5241989  0.469297   0.41831657]]\n",
      "\n",
      " [[0.6284483  0.5774679  0.5460953 ]\n",
      "  [0.62867975 0.57769936 0.5463268 ]\n",
      "  [0.6289112  0.5779308  0.54655826]\n",
      "  ...\n",
      "  [0.6384101  0.58350813 0.53252774]\n",
      "  [0.5815183  0.52661633 0.4756359 ]\n",
      "  [0.5200327  0.46513078 0.41415036]]\n",
      "\n",
      " [[0.62245893 0.57147855 0.540106  ]\n",
      "  [0.6203759  0.5693954  0.5380229 ]\n",
      "  [0.61829275 0.56731236 0.5359398 ]\n",
      "  ...\n",
      "  [0.6400303  0.58512837 0.5341479 ]\n",
      "  [0.5886934  0.5337914  0.482811  ]\n",
      "  [0.5158665  0.46096456 0.40998417]]]\n"
     ]
    }
   ],
   "source": [
    "for image_batch, label_batch in train_generator:\n",
    "    print(image_batch[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6df4aa3d-fdbb-42f4-81e4-c8ec573516fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1597 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen=ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range = 10,\n",
    "    \n",
    ")\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    'dataset/val',\n",
    "    target_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'sparse',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd34b7a7-c100-493d-b3bb-c21c8aee345f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3211 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range = 10,\n",
    "    \n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'dataset/test',\n",
    "    target_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'sparse',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c312cc-cfbd-4c9d-b752-87c1fcb981c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (715674334.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    layers.InputLayer(input_shape=input_shape)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "input_shape=(BATCH_SIZE, IMAGE_SIZE,IMAGE_SIZE,CHANNELS)\n",
    "n_classes = 10\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=input_shape),\n",
    "    layers.Conv2D(32,kernel_size = (3,3),activation=\"relu\"),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Conv2D(64,kernel_size = (3,3),activation=\"relu\"),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Conv2D(64,kernel_size = (3,3),activation=\"relu\"),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Conv2D(64,(3,3),activation=\"relu\"),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Conv2D(64,(3,3),activation=\"relu\"),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation = \"relu\"),\n",
    "    layers.Dense(n_classes,activation = \"softmax\"),\n",
    "    \n",
    "])\n",
    "model.build(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d8228-e412-4a69-995c-f39db4719c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
